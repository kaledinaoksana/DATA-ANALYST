{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5 - Basic Math and Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import randn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment 1 - Using NumPy to perform arithmetic operations on data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating arrays using a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,3,4,5,6])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10, 20, 20],\n",
       "       [40, 50, 60]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.array([[10,20,20],[40,50,60]])\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating arrays via assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  8.22,  36.97, -30.23, -21.28, -34.45,  -8.  ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(25)\n",
    "c = 36*np.random.randn(6)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = np.arange(1, 35)\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing arthimetic on arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 20 30 40 50 60]\n",
      "[  9.22  38.97 -27.23 -17.28 -29.45  -2.  ]\n",
      "[  7.22  34.97 -33.23 -25.28 -39.45 -14.  ]\n",
      "[   8.22   73.94  -90.68  -85.13 -172.24  -48.02]\n",
      "[  8.22  18.48 -10.08  -5.32  -6.89  -1.33]\n"
     ]
    }
   ],
   "source": [
    "print(a*10)\n",
    "print(c + a)\n",
    "print(c-a)\n",
    "print(c*a)\n",
    "print(c/a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.  4.  6.]\n",
      " [ 1.  3.  5.]\n",
      " [10. 20. 30.]]\n",
      "-------------------\n",
      "[[0. 1. 2.]\n",
      " [3. 4. 5.]\n",
      " [6. 7. 8.]]\n"
     ]
    }
   ],
   "source": [
    "### Multiplying matrices and basic linear algebra\n",
    "aa = np.array([[2.,4.,6.],[1.,3.,5.],[10.,20.,30.]])\n",
    "print(aa)\n",
    "print('-------------------')\n",
    "bb = np.array([[0.,1.,2.],[3.,4.,5.],[6.,7.,8.]])\n",
    "print(bb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.   4.  12.]\n",
      " [  3.  12.  25.]\n",
      " [ 60. 140. 240.]]\n"
     ]
    }
   ],
   "source": [
    "print(aa*bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 48.,  60.,  72.],\n",
       "       [ 39.,  48.,  57.],\n",
       "       [240., 300., 360.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(aa,bb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment 2 - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chapter 5 - Basic Math and Statistics\n",
    "## Segment 2 - Multiplying matrices and basic linear algebra\n",
    "import numpy as np\n",
    "from numpy.random import randn\n",
    "np.set_printoptions(precision=2)\n",
    "## Multiplying matrices and basic linear algebra\n",
    "aa = np.array([[2.,4.,6.],[1.,3.,5.],[10.,20.,30.]])\n",
    "aa\n",
    "bb = np.array([[0.,1.,2.],[3.,4.,5.],[6.,7.,8.]])\n",
    "bb\n",
    "aa*bb\n",
    "np.dot(aa,bb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment 3 - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chapter 5 - Basic Math and Statistics\n",
    "## Segment 3 - Generating summary statistics using pandas and scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "import scipy\n",
    "from scipy import stats\n",
    "address = 'C:/Users/Lillian/Desktop/ExerciseFiles/Data/mtcars.csv'\n",
    "\n",
    "cars = pd.read_csv(address)\n",
    "cars.columns = ['car_names','mpg','cyl','disp','hp','drat','wt','qsec','vs','am','gear','carb']\n",
    "\n",
    "cars.head()\n",
    "### Looking at summary statistics that decribe a variable's numeric values\n",
    "cars.sum()\n",
    "cars.sum(axis=1)\n",
    "cars.median()\n",
    "cars.mean()\n",
    "cars.max()\n",
    "mpg = cars.mpg\n",
    "mpg.idxmax()\n",
    "### Looking at summary statistics that describe variable distribution\n",
    "cars.std()\n",
    "cars.var()\n",
    "gear = cars.gear\n",
    "gear.value_counts()\n",
    "cars.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment 4 - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chapter 5 - Basic Math and Statistics\n",
    "## Segment 4 - Summarizing categorical data using pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "### The basics\n",
    "address = 'C:/Users/Lillian/Desktop/ExerciseFiles/Data/mtcars.csv'\n",
    "cars = pd.read_csv(address)\n",
    "\n",
    "cars.columns = ['car_names','mpg','cyl','disp','hp','drat','wt','qsec','vs','am','gear','carb']\n",
    "cars.index = cars.car_names\n",
    "cars.head(15)\n",
    "carb = cars.carb\n",
    "carb.value_counts()\n",
    "cars_cat = cars[['cyl','vs','am','gear','carb']]\n",
    "cars_cat.head()\n",
    "gears_group = cars_cat.groupby('gear')\n",
    "gears_group.describe()\n",
    "### Transforming variables to categorical data type\n",
    "cars['group'] = pd.Series(cars.gear, dtype=\"category\")\n",
    "cars['group'].dtypes\n",
    "cars['group'].value_counts()\n",
    "### Describing categorical data with crosstabs\n",
    "pd.crosstab(cars['am'], cars['gear'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment 5 - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chapter 5 - Basic Math and Statistics\n",
    "\n",
    "## Segment 5 - Starting with parametric methods in pandas and scipy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from pylab import rcParams\n",
    "\n",
    "import scipy\n",
    "from scipy.stats.stats import pearsonr\n",
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = 8,4\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "### The Pearson Correlation\n",
    "address = 'C:/Users/Lillian/Desktop/ExerciseFiles/Data/mtcars.csv'\n",
    "\n",
    "cars = pd.read_csv(address)\n",
    "cars.columns = ['car_names','mpg','cyl','disp','hp','drat','wt','qsec','vs','am','gear','carb']\n",
    "sb.pairplot(cars)\n",
    "X = cars[['mpg', 'hp', 'qsec', 'wt']]\n",
    "sb.pairplot(X)\n",
    "### Using scipy to calculate the Pearson correlation coefficient\n",
    "mpg = cars['mpg']\n",
    "hp = cars['hp']\n",
    "qsec = cars['qsec']\n",
    "wt = cars['wt']\n",
    "\n",
    "pearsonr_coefficient, p_value = pearsonr(mpg, hp)\n",
    "print('PeasonR Correlation Coefficient %0.3f'% (pearsonr_coefficient))\n",
    "pearsonr_coefficient, p_value = pearsonr(mpg, qsec)\n",
    "print('PeasonR Correlation Coefficient %0.3f'% (pearsonr_coefficient))\n",
    "pearsonr_coefficient, p_value = pearsonr(mpg, wt)\n",
    "print('PeasonR Correlation Coefficient %0.3f'% (pearsonr_coefficient))\n",
    "### Using pandas to calculate the Pearson correlation coefficient\n",
    "corr = X.corr()\n",
    "corr\n",
    "### Using Seaborn to visualize the Pearson correlation coefficient\n",
    "sb.heatmap(corr, xticklabels=corr.columns.values, yticklabels= corr.columns.values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment 6 - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chapter 5 - Basic Math and Statistics\n",
    "## Segment 6 - Delving into non-parametric methods using pandas and scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from pylab import rcParams\n",
    "\n",
    "import scipy\n",
    "from scipy.stats import spearmanr\n",
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = 14, 7\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "### The Spearman Rank Correlation\n",
    "address = 'C:/Users/Lillian/Desktop/ExerciseFiles/Data/mtcars.csv'\n",
    "\n",
    "cars = pd.read_csv(address)\n",
    "cars.columns = ['car_names','mpg','cyl','disp', 'hp', 'drat', 'wt', 'qsec', 'vs', 'am', 'gear', 'carb']\n",
    "cars.head()\n",
    "sb.pairplot(cars)\n",
    "X = cars[['cyl', 'vs', 'am', 'gear']]\n",
    "sb.pairplot(X)\n",
    "cyl = cars['cyl']\n",
    "vs = cars['vs']\n",
    "am = cars['am']\n",
    "gear = cars['gear']\n",
    "\n",
    "spearmanr_coefficient, p_value = spearmanr(cyl, vs)\n",
    "\n",
    "print('Spearman Rank Correlation Coefficient %0.3f' % (spearmanr_coefficient))\n",
    "spearmanr_coefficient, p_value = spearmanr(cyl, am)\n",
    "\n",
    "print('Spearman Rank Correlation Coefficient %0.3f' % (spearmanr_coefficient))\n",
    "spearmanr_coefficient, p_value = spearmanr(cyl, gear)\n",
    "\n",
    "print('Spearman Rank Correlation Coefficient %0.3f' % (spearmanr_coefficient))\n",
    "### Chi-square test for independence\n",
    "table = pd.crosstab(cyl, am)\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "chi2, p, dof, expected = chi2_contingency(table.values)\n",
    "print ('Chi-square statistic %0.3f p_value %0.3f' % (chi2, p))\n",
    "table = pd.crosstab(cyl, vs)\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "chi2, p, dof, expected = chi2_contingency(table.values)\n",
    "print ('Chi-square statistic %0.3f p_value %0.3f' % (chi2, p))\n",
    "table = pd.crosstab(cyl, gear)\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "chi2, p, dof, expected = chi2_contingency(table.values)\n",
    "print ('Chi-square statistic %0.3f p_value %0.3f' % (chi2, p))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment 7 - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chapter 5 - Basic Math and Statistics\n",
    "## Segment 7 - Transforming dataset distributions\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import seaborn as sb\n",
    "\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import scale\n",
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = 5, 4\n",
    "sb.set_style('whitegrid')\n",
    "### Normalizing and transforming features with MinMaxScalar() and fit_transform()\n",
    "address = 'C:/Users/Lillian/Desktop/ExerciseFiles/Data/mtcars.csv'\n",
    "\n",
    "cars = pd.read_csv(address)\n",
    "cars.columns = ['car_names','mpg','cyl','disp', 'hp', 'drat', 'wt', 'qsec', 'vs', 'am', 'gear', 'carb']\n",
    "mpg = cars.mpg\n",
    "plt.plot(mpg)\n",
    "cars[['mpg']].describe()\n",
    "mpg_matrix = mpg.values.reshape(-1,1)\n",
    "\n",
    "scaled = preprocessing.MinMaxScaler()\n",
    "\n",
    "scaled_mpg = scaled.fit_transform(mpg_matrix)\n",
    "plt.plot(scaled_mpg)\n",
    "scaled = preprocessing.MinMaxScaler(feature_range=(0,10))\n",
    "\n",
    "scaled_mpg = scaled.fit_transform(mpg_matrix)\n",
    "plt.plot(scaled_mpg)\n",
    "### Using scale() to scale your features\n",
    "standardized_mpg = scale(mpg, axis=0, with_mean=False, with_std=False)\n",
    "plt.plot(standardized_mpg)\n",
    "standardized_mpg = scale(mpg)\n",
    "plt.plot(standardized_mpg)\n",
    "http://goo.gl/tuEWkD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment 8 - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chapter 5 - Outlier Analysis\n",
    "## Segment 8 - Extreme value analysis using univariate methods\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = 5,4\n",
    "address = 'C:/Users/Lillian/Desktop/ExerciseFiles/Data/iris.data.csv'\n",
    "df = pd.read_csv(filepath_or_buffer=address, header=None, sep=',')\n",
    "\n",
    "df.columns=['Sepal Length','Sepal Width','Petal Length','Petal Width', 'Species']\n",
    "X = df.iloc[:,0:4].values\n",
    "y = df.iloc[:,4].values\n",
    "df[:5]\n",
    "### Identifying outliers from Tukey boxplots\n",
    "df.boxplot(return_type='dict')\n",
    "plt.plot()\n",
    "Sepal_Width = X[:,1]\n",
    "iris_outliers = (Sepal_Width > 4)\n",
    "df[iris_outliers]\n",
    "Sepal_Width = X[:,1]\n",
    "iris_outliers = (Sepal_Width < 2.05)\n",
    "df[iris_outliers]\n",
    "### Applying Tukey outlier labeling\n",
    "pd.options.display.float_format = '{:.1f}'.format\n",
    "X_df = pd.DataFrame(X)\n",
    "print(X_df.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment 9 - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chapter 5 - Outlier Analysis\n",
    "## Segment 8 - Extreme value analysis using univariate methods\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = 5,4\n",
    "address = 'C:/Users/Lillian/Desktop/ExerciseFiles/Data/iris.data.csv'\n",
    "df = pd.read_csv(filepath_or_buffer=address, header=None, sep=',')\n",
    "\n",
    "df.columns=['Sepal Length','Sepal Width','Petal Length','Petal Width', 'Species']\n",
    "X = df.iloc[:,0:4].values\n",
    "y = df.iloc[:,4].values\n",
    "df[:5]\n",
    "### Identifying outliers from Tukey boxplots\n",
    "df.boxplot(return_type='dict')\n",
    "plt.plot()\n",
    "Sepal_Width = X[:,1]\n",
    "iris_outliers = (Sepal_Width > 4)\n",
    "df[iris_outliers]\n",
    "Sepal_Width = X[:,1]\n",
    "iris_outliers = (Sepal_Width < 2.05)\n",
    "df[iris_outliers]\n",
    "### Applying Tukey outlier labeling\n",
    "pd.options.display.float_format = '{:.1f}'.format\n",
    "X_df = pd.DataFrame(X)\n",
    "print(X_df.describe())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "num-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
